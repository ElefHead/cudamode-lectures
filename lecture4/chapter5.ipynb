{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.cpp_extension import load\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication - Global Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ganesh/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ganesh/.cache/torch_extensions/py310_cu121/ops/build.ninja...\n",
      "Building extension module ops...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module ops...\n"
     ]
    }
   ],
   "source": [
    "mmul_module = load(\n",
    "    name=\"ops\",\n",
    "    sources=[\"csrc/matrix_multiply.cu\"], \n",
    "    extra_cuda_cflags=['--ptxas-options=-v', \"-O2\", \"-Xcompiler\", \"-Werror\", \"-Xcompiler\", \"-Wall\"], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.Generator(device='cuda:0')\n",
    "gen.manual_seed(42)\n",
    "\n",
    "m = 1024\n",
    "n = 1024\n",
    "k = 1024\n",
    "\n",
    "a = torch.randn(size=(m, k), dtype=torch.float32, device='cuda:0', generator=gen).contiguous()\n",
    "b = torch.randn(size=(k, n), dtype=torch.float32, device='cuda:0', generator=gen).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 384 µs, sys: 293 µs, total: 677 µs\n",
      "Wall time: 684 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "mmul_global_memory = mmul_module.ops.matrix_multiply_2d_op(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmul_global_memory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-18 00:46:01 170879:170879 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-18 00:46:03 170879:170879 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-18 00:46:03 170879:170879 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         3.59%      67.109ms         3.59%      67.109ms       6.711us       0.000us         0.00%       0.000us       0.000us         10000  \n",
      "                                       cudaLaunchKernel        95.57%        1.786s        95.57%        1.786s     178.598us       0.000us         0.00%       0.000us       0.000us         10000  \n",
      "matrix_multiply_2d_kernel(float const*, float const*...         0.00%       0.000us         0.00%       0.000us       0.000us        1.671s       100.00%        1.671s     167.113us         10000  \n",
      "                                  cudaDeviceSynchronize         0.84%      15.701ms         0.84%      15.701ms       1.570us       0.000us         0.00%       0.000us       0.000us         10001  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.869s\n",
      "Self CUDA time total: 1.671s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "    for i in range(10000):\n",
    "        mmul_module.ops.matrix_multiply_2d_op(a, b)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "print(prof.key_averages())\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai = 60.23529411764706\n"
     ]
    }
   ],
   "source": [
    "ai = m*n*k / (m*n + n*k + m*n)\n",
    "print(f\"{ai = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ganesh/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
      "The input conditions for extension module ops have changed. Bumping to version 1 and re-building as ops_v1...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ganesh/.cache/torch_extensions/py310_cu121/ops/build.ninja...\n",
      "Building extension module ops_v1...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output matrix_multiply_tiled.cuda.o.d -DTORCH_EXTENSION_NAME=ops_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ganesh/.local/share/virtualenvs/cudamode-lectures-SlOoH9rC/lib/python3.10/site-packages/torch/include -isystem /home/ganesh/.local/share/virtualenvs/cudamode-lectures-SlOoH9rC/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ganesh/.local/share/virtualenvs/cudamode-lectures-SlOoH9rC/lib/python3.10/site-packages/torch/include/TH -isystem /home/ganesh/.local/share/virtualenvs/cudamode-lectures-SlOoH9rC/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ganesh/.pyenv/versions/3.10.13/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' --ptxas-options=-v -O2 -Xcompiler -Werror -Xcompiler -Wall -std=c++17 -c /home/ganesh/workspace/python/cudamode-lectures/lecture4/csrc/matrix_multiply_tiled.cu -o matrix_multiply_tiled.cuda.o \n",
      "ptxas info    : 3 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z28matrix_multiply_tiled_kernelPfS_S_iii' for 'sm_75'\n",
      "ptxas info    : Function properties for _Z28matrix_multiply_tiled_kernelPfS_S_iii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 42 registers, 8192 bytes smem, 388 bytes cmem[0]\n",
      "[2/2] c++ matrix_multiply_tiled.cuda.o -shared -L/home/ganesh/.local/share/virtualenvs/cudamode-lectures-SlOoH9rC/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o ops_v1.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module ops_v1...\n"
     ]
    }
   ],
   "source": [
    "mmul_tiled_module = load(\n",
    "    name=\"ops\",\n",
    "    sources=[\"csrc/matrix_multiply_tiled.cu\"], \n",
    "    extra_cuda_cflags=['--ptxas-options=-v', \"-O2\", \"-Xcompiler\", \"-Werror\", \"-Xcompiler\", \"-Wall\"], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 10.3 ms, total: 10.3 ms\n",
      "Wall time: 10.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "mmu_tiled = mmul_tiled_module.ops.matrix_multiply_tiled(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-18 00:33:54 170879:170879 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-03-18 00:33:57 170879:170879 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-18 00:33:57 170879:170879 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         3.22%      66.321ms         3.22%      66.321ms       6.632us       0.000us         0.00%       0.000us       0.000us         10000  \n",
      "                                       cudaLaunchKernel        96.26%        1.985s        96.26%        1.985s     198.516us       0.000us         0.00%       0.000us       0.000us         10000  \n",
      "matrix_multiply_tiled_kernel(float*, float*, float*,...         0.00%       0.000us         0.00%       0.000us       0.000us        1.889s       100.00%        1.889s     188.895us         10000  \n",
      "                                  cudaDeviceSynchronize         0.52%      10.741ms         0.52%      10.741ms       1.074us       0.000us         0.00%       0.000us       0.000us         10001  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.062s\n",
      "Self CUDA time total: 1.889s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile() as prof:\n",
    "    for i in range(10000):\n",
    "        mmul_tiled_module.ops.matrix_multiply_tiled(a, b)\n",
    "        torch.cuda.synchronize()\n",
    "print(prof.key_averages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 ms, sys: 7.75 ms, total: 25.8 ms\n",
      "Wall time: 24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "c = a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(mmu_tiled, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudamode-lectures-SlOoH9rC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
